{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import glob , numpy\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import html\n",
    "import csv\n",
    "import math\n",
    "import unicodedata\n",
    "import nltk\n",
    "from collections import Counter \n",
    "\n",
    "\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCHOONMAKEN!!!!!!#############\n",
    "def strip_accents(text):\n",
    "\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "\n",
    "    return str(text)\n",
    "\n",
    "\n",
    "def clean(review):\n",
    "    #try:\n",
    "        #review = review.apply(lambda x: x.lower())\n",
    "    review = review.replace('[^\\w\\s]','')\n",
    "    review = review.replace('\\r', '')\n",
    "    review = review.replace('\\n', '')\n",
    "    review = review.replace('&#246;', 'e')\n",
    "    review = review.replace('&#233;', 'e')\n",
    "    review = review.replace('&#235;', 'e')\n",
    "    review = review.replace('&#8364;', '')\n",
    "    review = review.replace('&#239;', 'i')\n",
    "    review = review.replace('&#8226;', 'i')\n",
    "    review = review.replace('&apos;', '')\n",
    "    review = review.replace('#215;', '/')\n",
    "    review = review.replace('&amp;', '')\n",
    "    review = review.replace('&#8230;', '')\n",
    "    review = review.replace('&apos;', '')\n",
    "    review = review.replace('&#225;', '')\n",
    "    review = review.replace('&quot;', '')\n",
    "\n",
    "\n",
    "    review = strip_accents(review)\n",
    "    return review\n",
    "    #except:\n",
    "    #    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INSERT HERE LOAD CSV WITH LIST OF LISTS REVIEWS PER MOVIE\n",
    "path=\"E:\\Crawledmovies\\*.txt\"\n",
    "files = glob.glob(path)\n",
    "\n",
    "titlelist=[]\n",
    "yearlist = []\n",
    "imdburllist=[]\n",
    "reviews=[]\n",
    "\n",
    "totalFileCount = len(files)\n",
    "for file in files:\n",
    "    templist=[]\n",
    "    #print(\"file: \", file)\n",
    "    myfile = open(file, 'r',encoding=\"utf8\")\n",
    "    soup = BeautifulSoup(myfile.read(), \"html.parser\")\n",
    "    #print(\"tags: \", soup.find(\"meta\", property=\"og:title\")['content'])\n",
    "    metaTag = soup.find(\"meta\", property=\"og:title\")['content'].split(\"(\")\n",
    "    title = metaTag[:-1][0]\n",
    "    yearpart = re.findall('\\d+', metaTag[-1])\n",
    "    year = yearpart[0] if len(yearpart) == 1 else yearpart[0] + \"-\" + yearpart[1]\n",
    "    for x in soup.findAll(\"div\", class_=\"text show-more__control\")[:50]:\n",
    "        x=clean(x.text)\n",
    "        templist.append([x])\n",
    "\n",
    "    if title is None:\n",
    "        continue #jump to next file: If there is no title, we ignore the file\n",
    "    else:\n",
    "        titlelist.append(title)\n",
    "        if year is None:\n",
    "            yearlist.append('')\n",
    "        else:\n",
    "            yearlist.append(year)\n",
    "        if templist is None:\n",
    "            reviews.append(\"\")\n",
    "        else:\n",
    "            reviews.append(templist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>1999</td>\n",
       "      <td>[[** May contain spoilers **There aren't many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batman Begins</td>\n",
       "      <td>2005</td>\n",
       "      <td>[[This film easily trumps any live-action inca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man of Steel</td>\n",
       "      <td>2013</td>\n",
       "      <td>[[At first I was very nervous at the prospect ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  year                                            summary\n",
       "0     The Matrix   1999  [[** May contain spoilers **There aren't many ...\n",
       "1  Batman Begins   2005  [[This film easily trumps any live-action inca...\n",
       "2   Man of Steel   2013  [[At first I was very nervous at the prospect ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'title': titlelist,\"year\":yearlist, \"summary\":reviews})\n",
    "#data.to_csv(\"imdbclean.csv\", encoding='utf-8', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "#### FROM HERE REAL SENTIMENT ANALYSIS CODE######################\n",
    "nltk.download('popular')\n",
    "\n",
    "# A function that extracts which words exist in a text based on a list of words to which we compare.\n",
    "def word_feats(words):\n",
    "        return dict([(word, True) for word in words])\n",
    "\n",
    "# Get the negative reviews for movies    \n",
    "negids = movie_reviews.fileids('neg')\n",
    "\n",
    "# Get the positive reviews for movies\n",
    "posids = movie_reviews.fileids('pos')\n",
    " \n",
    "# Find the features that most correspond to negative reviews    \n",
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "\n",
    "# Find the features that most correspond to positive reviews\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "# We would only use 1500 instances to train on. The quarter of the reviews left is for testing purposes.\n",
    "negcutoff = int(len(negfeats)*3/4)\n",
    "poscutoff = int(len(posfeats)*3/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1500 instances, test on 500 instances\n",
      "accuracy: 0.728\n",
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Construct the training dataset containing 50% positive reviews and 50% negative reviews\n",
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "\n",
    "# Construct the negative dataset containing 50% positive reviews and 50% negative reviews\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "\n",
    "print ('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n",
    "\n",
    "# Train a NaiveBayesClassifier\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "\n",
    "# Test the trained classifier and display the most informative features.\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "classifier.show_most_informative_features()\n",
    "\n",
    "def create_word_features(words):\n",
    "    useful_words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    my_dict = dict([(word, True) for word in useful_words])\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "finallist=[]\n",
    "\n",
    "for movie in data[\"summary\"]:\n",
    "    templist=[]\n",
    "    for x in movie:\n",
    "        words = word_tokenize(str(x))\n",
    "        words = create_word_features(words)\n",
    "        output=classifier.classify(words)\n",
    "        templist.append(output)\n",
    "        ratings=Counter(templist)\n",
    "    finallist.append(ratings)     \n",
    "  \n",
    "data[\"sentiment\"]=finallist\n",
    "df1=pd.DataFrame(data['sentiment'].values.tolist(), index=data.index)\n",
    "df=pd.concat([data, df1],  axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>summary</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>1999</td>\n",
       "      <td>[[** May contain spoilers **There aren't many ...</td>\n",
       "      <td>{'pos': 32, 'neg': 18}</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batman Begins</td>\n",
       "      <td>2005</td>\n",
       "      <td>[[This film easily trumps any live-action inca...</td>\n",
       "      <td>{'pos': 41, 'neg': 9}</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man of Steel</td>\n",
       "      <td>2013</td>\n",
       "      <td>[[At first I was very nervous at the prospect ...</td>\n",
       "      <td>{'pos': 32, 'neg': 18}</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  year                                            summary  \\\n",
       "0     The Matrix   1999  [[** May contain spoilers **There aren't many ...   \n",
       "1  Batman Begins   2005  [[This film easily trumps any live-action inca...   \n",
       "2   Man of Steel   2013  [[At first I was very nervous at the prospect ...   \n",
       "\n",
       "                sentiment  neg  pos  \n",
       "0  {'pos': 32, 'neg': 18}   18   32  \n",
       "1   {'pos': 41, 'neg': 9}    9   41  \n",
       "2  {'pos': 32, 'neg': 18}   18   32  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
