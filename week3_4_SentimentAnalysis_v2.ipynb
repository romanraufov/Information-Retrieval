{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "###################\n",
    "\n",
    "# First version of the sentiment analysis\n",
    "# in short, it goes through the first couple of entered tweets \n",
    "# of which the sentiment has to be determined\n",
    "# the classifyer is then trained\n",
    "# A tweet can then be classified and\n",
    "# a simple function determines the further sentiment \n",
    "# (for or against Hillary/Trump)\n",
    "# by simply counting whom is mentioned more in the tweet\n",
    "\n",
    "# To test if it all kinda works, there is an automatic sentiment provider\n",
    "# which assigns a sentiment to a tweet based on a coinflip\n",
    "# you'll pass by this when you run the scripts\n",
    "\n",
    "\n",
    "# Problems:\n",
    "###########\n",
    "# URL's in tweets\n",
    "# names in tweets, names are going to be associated to a certain sentiment,\n",
    "# which should not be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "# Import all the libraries required\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import rgb2hex\n",
    "from descartes import PolygonPatch\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# This snippet downloads the most popular datasets for experimenting with NLTK functionalities.\n",
    "import nltk\n",
    "nltk.download('popular')\n",
    "\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>locationName</th>\n",
       "      <th>long</th>\n",
       "      <th>text</th>\n",
       "      <th>trumpOrHillary</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ba60d5d286c6420bce62bea</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri Aug 12 10:04:00 +0000 2016</td>\n",
       "      <td>764039724818272256</td>\n",
       "      <td>38.627027</td>\n",
       "      <td>Frontenac</td>\n",
       "      <td>-90.419685</td>\n",
       "      <td>theblaze realdonaldtrump</td>\n",
       "      <td>trump</td>\n",
       "      <td>366636488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ba60d5d286c6420bce62beb</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri Aug 12 10:04:02 +0000 2016</td>\n",
       "      <td>764039733076897792</td>\n",
       "      <td>30.459100</td>\n",
       "      <td>Baton Rouge</td>\n",
       "      <td>-91.090800</td>\n",
       "      <td>barackobama fbi lorettalynch collusion togethe...</td>\n",
       "      <td>trump</td>\n",
       "      <td>82496193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5ba60d5d286c6420bce62bec</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri Aug 12 10:04:10 +0000 2016</td>\n",
       "      <td>764039769244348417</td>\n",
       "      <td>38.627027</td>\n",
       "      <td>Frontenac</td>\n",
       "      <td>-90.419685</td>\n",
       "      <td>theblaze realdonaldtrump</td>\n",
       "      <td>trump</td>\n",
       "      <td>366636488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ba60d5d286c6420bce62bed</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "      <td>Fri Aug 12 10:04:21 +0000 2016</td>\n",
       "      <td>764039812479225856</td>\n",
       "      <td>-37.972566</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>145.053135</td>\n",
       "      <td>hillaryclinton one year thing done eight</td>\n",
       "      <td>hillary</td>\n",
       "      <td>44032624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ba60d5d286c6420bce62bee</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri Aug 12 10:04:30 +0000 2016</td>\n",
       "      <td>764039849850482689</td>\n",
       "      <td>39.284713</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>-76.620482</td>\n",
       "      <td>cnn newday clear trump deliberately throwing r...</td>\n",
       "      <td>trump</td>\n",
       "      <td>769208504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id        country country_code  \\\n",
       "0  5ba60d5d286c6420bce62bea  United States           US   \n",
       "1  5ba60d5d286c6420bce62beb  United States           US   \n",
       "2  5ba60d5d286c6420bce62bec  United States           US   \n",
       "3  5ba60d5d286c6420bce62bed      Australia           AU   \n",
       "4  5ba60d5d286c6420bce62bee  United States           US   \n",
       "\n",
       "                       created_at                  id        lat locationName  \\\n",
       "0  Fri Aug 12 10:04:00 +0000 2016  764039724818272256  38.627027    Frontenac   \n",
       "1  Fri Aug 12 10:04:02 +0000 2016  764039733076897792  30.459100  Baton Rouge   \n",
       "2  Fri Aug 12 10:04:10 +0000 2016  764039769244348417  38.627027    Frontenac   \n",
       "3  Fri Aug 12 10:04:21 +0000 2016  764039812479225856 -37.972566    Melbourne   \n",
       "4  Fri Aug 12 10:04:30 +0000 2016  764039849850482689  39.284713    Baltimore   \n",
       "\n",
       "         long                                               text  \\\n",
       "0  -90.419685                           theblaze realdonaldtrump   \n",
       "1  -91.090800  barackobama fbi lorettalynch collusion togethe...   \n",
       "2  -90.419685                           theblaze realdonaldtrump   \n",
       "3  145.053135           hillaryclinton one year thing done eight   \n",
       "4  -76.620482  cnn newday clear trump deliberately throwing r...   \n",
       "\n",
       "  trumpOrHillary       user  \n",
       "0          trump  366636488  \n",
       "1          trump   82496193  \n",
       "2          trump  366636488  \n",
       "3        hillary   44032624  \n",
       "4          trump  769208504  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "db = client[\"Fundamentals_34\"]\n",
    "\n",
    "fieldsToSelect = { \"_id\": 1, \"created_at\": 1, \"text\": 1, \"coordinates\": 1, \"place\": 1 }\n",
    "tweet_data = db.preprocessedTweets.find({}).limit(2000)\n",
    "df = pd.DataFrame(list(tweet_data))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "\n",
    "# A function that extracts which words exist in a text based on a list of words to which we compare.\n",
    "def word_feats(words):\n",
    "        return dict([(word, True) for word in words])\n",
    "\n",
    "# Get the negative reviews for movies    \n",
    "negids = movie_reviews.fileids('neg')\n",
    "\n",
    "# Get the positive reviews for movies\n",
    "posids = movie_reviews.fileids('pos')\n",
    " \n",
    "# Find the features that most correspond to negative reviews    \n",
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "\n",
    "# Find the features that most correspond to positive reviews\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "# We would only use 1500 instances to train on. The quarter of the reviews left is for testing purposes.\n",
    "negcutoff = int(len(negfeats)*3/4)\n",
    "poscutoff = int(len(posfeats)*3/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1500 instances, test on 500 instances\n",
      "accuracy: 0.728\n",
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Construct the training dataset containing 50% positive reviews and 50% negative reviews\n",
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "\n",
    "# Construct the negative dataset containing 50% positive reviews and 50% negative reviews\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "\n",
    "print ('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n",
    "\n",
    "# Train a NaiveBayesClassifier\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "\n",
    "# Test the trained classifier and display the most informative features.\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>locationName</th>\n",
       "      <th>long</th>\n",
       "      <th>text</th>\n",
       "      <th>trumpOrHillary</th>\n",
       "      <th>user</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ba60d5d286c6420bce62bea</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri Aug 12 10:04:00 +0000 2016</td>\n",
       "      <td>764039724818272256</td>\n",
       "      <td>38.627027</td>\n",
       "      <td>Frontenac</td>\n",
       "      <td>-90.419685</td>\n",
       "      <td>theblaze realdonaldtrump</td>\n",
       "      <td>trump</td>\n",
       "      <td>366636488</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ba60d5d286c6420bce62beb</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri Aug 12 10:04:02 +0000 2016</td>\n",
       "      <td>764039733076897792</td>\n",
       "      <td>30.459100</td>\n",
       "      <td>Baton Rouge</td>\n",
       "      <td>-91.090800</td>\n",
       "      <td>barackobama fbi lorettalynch collusion togethe...</td>\n",
       "      <td>trump</td>\n",
       "      <td>82496193</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5ba60d5d286c6420bce62bec</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri Aug 12 10:04:10 +0000 2016</td>\n",
       "      <td>764039769244348417</td>\n",
       "      <td>38.627027</td>\n",
       "      <td>Frontenac</td>\n",
       "      <td>-90.419685</td>\n",
       "      <td>theblaze realdonaldtrump</td>\n",
       "      <td>trump</td>\n",
       "      <td>366636488</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ba60d5d286c6420bce62bed</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "      <td>Fri Aug 12 10:04:21 +0000 2016</td>\n",
       "      <td>764039812479225856</td>\n",
       "      <td>-37.972566</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>145.053135</td>\n",
       "      <td>hillaryclinton one year thing done eight</td>\n",
       "      <td>hillary</td>\n",
       "      <td>44032624</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ba60d5d286c6420bce62bee</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri Aug 12 10:04:30 +0000 2016</td>\n",
       "      <td>764039849850482689</td>\n",
       "      <td>39.284713</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>-76.620482</td>\n",
       "      <td>cnn newday clear trump deliberately throwing r...</td>\n",
       "      <td>trump</td>\n",
       "      <td>769208504</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id        country country_code  \\\n",
       "0  5ba60d5d286c6420bce62bea  United States           US   \n",
       "1  5ba60d5d286c6420bce62beb  United States           US   \n",
       "2  5ba60d5d286c6420bce62bec  United States           US   \n",
       "3  5ba60d5d286c6420bce62bed      Australia           AU   \n",
       "4  5ba60d5d286c6420bce62bee  United States           US   \n",
       "\n",
       "                       created_at                  id        lat locationName  \\\n",
       "0  Fri Aug 12 10:04:00 +0000 2016  764039724818272256  38.627027    Frontenac   \n",
       "1  Fri Aug 12 10:04:02 +0000 2016  764039733076897792  30.459100  Baton Rouge   \n",
       "2  Fri Aug 12 10:04:10 +0000 2016  764039769244348417  38.627027    Frontenac   \n",
       "3  Fri Aug 12 10:04:21 +0000 2016  764039812479225856 -37.972566    Melbourne   \n",
       "4  Fri Aug 12 10:04:30 +0000 2016  764039849850482689  39.284713    Baltimore   \n",
       "\n",
       "         long                                               text  \\\n",
       "0  -90.419685                           theblaze realdonaldtrump   \n",
       "1  -91.090800  barackobama fbi lorettalynch collusion togethe...   \n",
       "2  -90.419685                           theblaze realdonaldtrump   \n",
       "3  145.053135           hillaryclinton one year thing done eight   \n",
       "4  -76.620482  cnn newday clear trump deliberately throwing r...   \n",
       "\n",
       "  trumpOrHillary       user Sentiment  \n",
       "0          trump  366636488       pos  \n",
       "1          trump   82496193       pos  \n",
       "2          trump  366636488       pos  \n",
       "3        hillary   44032624       pos  \n",
       "4          trump  769208504       pos  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'] = df['text'].apply(lambda x: classifier.classify(word_feats(x.split())))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    1171\n",
       "neg     829\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Sentiment.csv')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
